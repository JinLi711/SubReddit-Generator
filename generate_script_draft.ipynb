{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinli/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import keras\n",
    "from keras.models import load_model\n",
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import random\n",
    "# import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('RNN_weights.best.hdf5')\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Compute new probability distribution based on the temperature\n",
    "    Higher temperature creates more randomness.\n",
    "\n",
    "    :param preds: numpy array of shape (unique chars,), and elements sum to 1\n",
    "    :type  preds: numpy.ndarray\n",
    "    :param temperature: characterizes the entropy of probability distribution\n",
    "    :type  temperature: float\n",
    "    :returns: a number 0 to the length of preds - 1\n",
    "    :rtype:   int\n",
    "    \"\"\"\n",
    "\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_generate(model, text, word_indices, maxlen=10, temperature=1.0, textlen=40):\n",
    "    \"\"\"\n",
    "    Generate text based on a model.\n",
    "\n",
    "    :param model: trained keras model\n",
    "    :type  model: keras.engine.sequential.Sequential\n",
    "    :param text: lyrics\n",
    "    :type  text: str\n",
    "    :param char_indices: dictionary mapping a character to its integer placeholder\n",
    "    :type  char_indices: dict\n",
    "    :param maxlen: maximum length of the sequences\n",
    "    :type  maxlen: int\n",
    "    :param textlen: Number of characters of generated sequence\n",
    "    :type  textlen: int\n",
    "    \"\"\"\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    full_sentence = \" \".join(generated_text)\n",
    "\n",
    "    out_text = generated_text\n",
    "\n",
    "    for i in range(textlen):\n",
    "\n",
    "        sampled = []\n",
    "        for t, word in enumerate(generated_text):\n",
    "            word_dimensions = list(wordvectors_mini[word])\n",
    "            sampled.append(word_dimensions)\n",
    "        sampled = np.array(sampled)\n",
    "        sampled = np.reshape(sampled, (1,) + sampled.shape)\n",
    "\n",
    "        preds = model.predict(sampled, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_index = str(next_index)\n",
    "        next_word = word_indices[next_index]\n",
    "\n",
    "        generated_text.append(next_word)\n",
    "        generated_text = generated_text[1:]\n",
    "        out_text.append(next_word)\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokens[:200]\n",
    "\n",
    "\n",
    "def find_random_sentence(tokens, word, maxlen):\n",
    "    list_of_appearance = np.where(np.array(tokens) == word)[0]\n",
    "    stop_characters = set({'...', '.', '?', '!'})\n",
    "    random_index = random.choice(list_of_appearance)\n",
    "    index = random_index\n",
    "\n",
    "    sentence = []\n",
    "    while (tokens[index] not in stop_characters):\n",
    "        sentence.append(tokens[index])\n",
    "        index += 1\n",
    "    sentence.append(tokens[index])\n",
    "\n",
    "    index = random_index\n",
    "\n",
    "    while ((tokens[index] not in stop_characters) or len(sentence) < 11):\n",
    "        sentence.insert(0, tokens[index])\n",
    "        index -= 1\n",
    "\n",
    "    return sentence[:maxlen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_generate_with_word(\n",
    "        model,\n",
    "        text,\n",
    "        word_indices,\n",
    "        word,\n",
    "        maxlen=10,\n",
    "        temperature=1.0,\n",
    "        textlen=40):\n",
    "    \"\"\"\n",
    "    Generate text based on a model.\n",
    "    The starting seed is based on a word input \n",
    "\n",
    "    :param model: trained keras model\n",
    "    :type  model: keras.engine.sequential.Sequential\n",
    "    :param text: lyrics\n",
    "    :type  text: str\n",
    "    :param char_indices: dictionary mapping a character to its integer placeholder\n",
    "    :type  char_indices: dict\n",
    "    :param word: the input starting word\n",
    "    :type  word: str\n",
    "    :param maxlen: maximum length of the sequences\n",
    "    :type  maxlen: int\n",
    "    :param textlen: Number of characters of generated sequence\n",
    "    :type  textlen: int\n",
    "    \"\"\"\n",
    "\n",
    "    stop_characters = set({'...', '.', '?', '!'})\n",
    "\n",
    "    generated_text = find_random_sentence(tokens, word, maxlen)\n",
    "    full_sentence = \" \".join(generated_text)\n",
    "\n",
    "    out_text = generated_text\n",
    "\n",
    "#     for i in range(textlen):\n",
    "    stop_generate = False\n",
    "    i = 0\n",
    "    while ((i < textlen) or (not stop_generate)):\n",
    "\n",
    "        sampled = []\n",
    "        for t, word in enumerate(generated_text):\n",
    "            word_dimensions = list(wordvectors_mini[word])\n",
    "            sampled.append(word_dimensions)\n",
    "        sampled = np.array(sampled)\n",
    "        sampled = np.reshape(sampled, (1,) + sampled.shape)\n",
    "\n",
    "        preds = model.predict(sampled, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_index = str(next_index)\n",
    "        next_word = word_indices[next_index]\n",
    "\n",
    "        generated_text.append(next_word)\n",
    "        generated_text = generated_text[1:]\n",
    "        out_text.append(next_word)\n",
    "\n",
    "        if (next_word in stop_characters):\n",
    "            stop_generate = True\n",
    "        i += 1\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this so I download the text after making this changes, so I can just upload th\n",
    "# updated text\n",
    "# actually, change it so \n",
    "import re\n",
    "text = open('all.txt', 'r').read()\n",
    "text = text.lower()\n",
    "text = re.sub(r'[*^$%&()@#-+_=//]', ' ', text)\n",
    "text = re.sub(\" \\d+\", \"number\", text)\n",
    "text = re.sub(r'http\\S+', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)\n",
    "with open('mapping.json') as infile:\n",
    "    word_indices = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens\n",
    "# word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordvectors_mini = json.loads('wordvectors_mini.json')#.decode(\"utf-8\")\n",
    "# wordvectors_mini = json.load('test.json')\n",
    "with open('wordvectors_mini.json') as infile:\n",
    "    wordvectors_mini = json.load(infile)\n",
    "# text_generate_with_word(model, tokens, word_indices, 'pizza')\n",
    "# test_csv = pd.read_csv('wordvectors_mini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_csv.to_dict()#.shape#.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_csv\n",
    "# wordvectors_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_text():\n",
    "    try: \n",
    "        sentence = text_generate_with_word(\n",
    "            model, tokens, word_indices, 'pizza', maxlen=20\n",
    "        )\n",
    "        final_text = ' '.join(sentence)\n",
    "    except ValueError:\n",
    "        sentence = text_generate(model, tokens, word_indices, maxlen=20)\n",
    "        final_text = ' '.join (sentence)\n",
    "    except KeyError:\n",
    "        gen_text()\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thank god lisa ann is still going strong pineapple on pizza is like the country music of pizza pizza . if if you else kind should nothing he looks like down to it . what is just a his can owned are the point ! if it was you what me , for , the first ask - the youre to'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final_text = ' '.join (text_generate(model, tokens, word_indices, maxlen=20))\n",
    "final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordvectors_mini['bynumber']#.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'language_check'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-309cc0798104>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlanguage_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'language_check'"
     ]
    }
   ],
   "source": [
    "import language_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
