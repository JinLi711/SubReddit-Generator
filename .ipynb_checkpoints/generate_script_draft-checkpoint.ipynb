{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinli/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import keras\n",
    "from keras.models import load_model\n",
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('RNN_weights.best.hdf5')\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Compute new probability distribution based on the temperature\n",
    "    Higher temperature creates more randomness.\n",
    "    \n",
    "    :param preds: numpy array of shape (unique chars,), and elements sum to 1\n",
    "    :type  preds: numpy.ndarray\n",
    "    :param temperature: characterizes the entropy of probability distribution\n",
    "    :type  temperature: float\n",
    "    :returns: a number 0 to the length of preds - 1\n",
    "    :rtype:   int\n",
    "    \"\"\"\n",
    "    \n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_generate(model, text, word_indices, maxlen=10, temperature=1.0, textlen=40):\n",
    "    \"\"\"\n",
    "    Generate text based on a model.\n",
    "    \n",
    "    :param model: trained keras model\n",
    "    :type  model: keras.engine.sequential.Sequential\n",
    "    :param text: lyrics\n",
    "    :type  text: str\n",
    "    :param char_indices: dictionary mapping a character to its integer placeholder\n",
    "    :type  char_indices: dict\n",
    "    :param maxlen: maximum length of the sequences\n",
    "    :type  maxlen: int\n",
    "    :param textlen: Number of characters of generated sequence\n",
    "    :type  textlen: int\n",
    "    \"\"\"\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1) \n",
    "    generated_text = text[start_index: start_index + maxlen] \n",
    "    full_sentence = \" \".join (generated_text)\n",
    "    print(len(generated_text))\n",
    "    print('--- Generating with seed: \"' + full_sentence + '\"')\n",
    "    \n",
    "    print('------ temperature:', temperature)\n",
    "    sys.stdout.write(full_sentence)\n",
    "    \n",
    "    \n",
    "    for i in range(textlen):\n",
    "        \n",
    "        sampled = []\n",
    "        for t, word in enumerate(generated_text):\n",
    "            word_dimensions = list (wordvectors_mini[word])\n",
    "            sampled.append(word_dimensions)\n",
    "        sampled = np.array(sampled)\n",
    "        sampled = np.reshape(sampled, (1,) + sampled.shape ) \n",
    "\n",
    "        preds = model.predict(sampled, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_word = word_indices[next_index]\n",
    "\n",
    "        generated_text.append ( next_word)\n",
    "        generated_text = generated_text[1:]\n",
    "        sys.stdout.write(\" \" + next_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokens[:200]\n",
    "\n",
    "def find_random_sentence(tokens, word, maxlen):\n",
    "    list_of_appearance = np.where(np.array(tokens) == word)[0]\n",
    "    stop_characters = set({'...', '.', '?', '!'})\n",
    "    random_index = random.choice(list_of_appearance)\n",
    "    index = random_index\n",
    "    \n",
    "    sentence = []\n",
    "    while (tokens[index] not in stop_characters):\n",
    "        sentence.append(tokens[index])\n",
    "        index += 1\n",
    "    sentence.append(tokens[index])\n",
    "    \n",
    "    index = random_index\n",
    "    \n",
    "    while ( (tokens[index] not in stop_characters) or len(sentence) < 11):\n",
    "        sentence.insert(0, tokens[index])\n",
    "        index -= 1\n",
    "    \n",
    "    return sentence[:maxlen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_generate_with_word(\n",
    "    model, \n",
    "    text, \n",
    "    word_indices,\n",
    "    word,\n",
    "    maxlen=10, \n",
    "    temperature=1.0,\n",
    "    textlen=40):\n",
    "    \"\"\"\n",
    "    Generate text based on a model.\n",
    "    The starting seed is based on a word input \n",
    "    \n",
    "    :param model: trained keras model\n",
    "    :type  model: keras.engine.sequential.Sequential\n",
    "    :param text: lyrics\n",
    "    :type  text: str\n",
    "    :param char_indices: dictionary mapping a character to its integer placeholder\n",
    "    :type  char_indices: dict\n",
    "    :param word: the input starting word\n",
    "    :type  word: str\n",
    "    :param maxlen: maximum length of the sequences\n",
    "    :type  maxlen: int\n",
    "    :param textlen: Number of characters of generated sequence\n",
    "    :type  textlen: int\n",
    "    \"\"\"\n",
    "    \n",
    "    stop_characters = set({'...', '.', '?', '!'})\n",
    "    \n",
    "    generated_text = find_random_sentence(tokens, word, maxlen)\n",
    "    full_sentence = \" \".join (generated_text)\n",
    "    print(len(generated_text))\n",
    "    print('--- Generating with seed: \"' + full_sentence + '\"')\n",
    "    \n",
    "    print('------ temperature:', temperature)\n",
    "    sys.stdout.write(full_sentence)\n",
    "    \n",
    "    out_text = generated_text\n",
    "    \n",
    "#     for i in range(textlen):\n",
    "    stop_generate = False\n",
    "    i = 0\n",
    "    while ( (i < textlen) or (not stop_generate) ):\n",
    "        \n",
    "        sampled = []\n",
    "        for t, word in enumerate(generated_text):\n",
    "            word_dimensions = list (wordvectors_mini[word])\n",
    "            sampled.append(word_dimensions)\n",
    "        sampled = np.array(sampled)\n",
    "        sampled = np.reshape(sampled, (1,) + sampled.shape ) \n",
    "\n",
    "        preds = model.predict(sampled, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_index = str(next_index)\n",
    "        next_word = word_indices[next_index]\n",
    "\n",
    "        generated_text.append ( next_word)\n",
    "        generated_text = generated_text[1:]\n",
    "        sys.stdout.write(\" \" + next_word)\n",
    "        out_text.append(next_word)\n",
    "        \n",
    "        if (next_word in stop_characters):\n",
    "            stop_generate = True\n",
    "        i += 1\n",
    "    return out_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = open('all.txt', 'r').read()\n",
    "text = text.lower()\n",
    "text = re.sub(r'[*^$%&()@#-+_=//]', ' ', text)\n",
    "text = re.sub(\" \\d+\", \"number\", text)\n",
    "text = re.sub(r'http\\S+', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'did you have your showerhead plugged in? or is it a wireless model?\\nyep. and when you finally switch to another career, it really throws you off when your coworkers measure years differently. \\nthats a nice dark thought that will now pop into my head during my next birthday...\\ni want to be cremated and then put into one of those cardboard pods that grows into a tree so one day i will be cut down and turned into someone elses coffin.\\nwould they think it’s cool if it was vomit?\\nu the only one thinking that bro\\ni wanted to get to know somebody better, so i asked them how their vaction went in mexico - simple enough right?   she told me to follow her instagram, where i could find out for myself.  at least it saved me the effort of getting to know them in the first place?  edit: i know, she probably wasnt interested in getting to know me, but a simple it was good would have gotten the message across just as well... \\nits just the outside catching up with the inside.\\ni am sorry detective; my responses are limited. you must ask the right questions.\\nwhat about the cheese and gravy\\nevian is naive spelled backwards\\ni think it would be scarier if it just randomly gave you a factoid about you based on what it knows. pretending it didnt know these things but slowly making you aware that it has mapped your entire life. \\nno bro is oil\\nwhat if the aliens doing that to us are only doing it because someone did it to them first? perhaps its the universes oldest interstellar prank.\\nthe only other white person who could get away with it is danny devito.\\nsame if you stomp on some rice crispies.\\ntechnically, youre giving them a bad week. or it feels like week for them.\\nthis is a good example of over-thinking it.  give fans long enough to obsess over a story and they will come up with theories inter-connecting every little thing...truth is hagrid and snape wouldnt get along whether harry existed or not, plus its clear during sorcerors stone that they already dont get along for many years beforehand.\\nsomeone at a stock brokerage i worked at would stick her dirty pads to the stall wall all the time. it disturbed me that someone i knew and worked with was so deliberately disgusting. \\nnot really... people starving in africa would be even more fucked\\nemphysema isnt something you would like to have\\nand be the only white girl that can\\nthank you for making sure i think about the fact that shes a family member the next time i have sex with my wife.  i really appreciate that.\\nthe other day, i walked by a man looking at his phone while his dog walked along, leaving a little trail of poos.  i thought maybe he didnt realize his dog was pooping, since he was paying attention to his phone and his dog hadnt stopped walking.  he did not appreciate me pointing this out to him.  \\nand their rehab just ends up being the opposite of rehab\\nwho knows?      maybe its just higher-dimensional advertising billboards. \\nthe best reasoning for something like this i heard is that fancy is just the opposite of how its normally worn.  i.e. someone who wears their hair down would put it up and vice versa.  not a universal truth, mind.\\ndoes duckduckgo ever get product placement?\\nhaha great insight!! \\nthats hot as hell. \\nokay, that’s mind-blowing\\nriding a ten speed down a flight of stairs. \\nor naming their kids boy and  girl\\nand then they see us and say the test subjects are still alive?\\n88 is justnumber for chubby people.\\ni could not imagine going to school for your entire life, which is part of why i am not gonna be a teacher. \\nsometimes thats way too literal, like in brazil where police and criminal group corruption can sometimes overlap with eachother\\nthere are more non virgins than virgins\\nmy daughters class hasnumber,000 students in it. and my wife says no flask. junenumber is gonna suck.  edit: was not expecting this response, but i have had a fun time reading all of your responses with my wife and daughter, who have found them hilarious. family fun night,number version. \\ni think itll be more impressive, because: number. accidents will be rare number. automated car accidents, even more rare\\ndrive-throughs that won’t serve pedestrians are basically saying they have a strict dress code that requires you to wear a car.\\nin the harry potter universe, couples could take polyjuice potion and swap bodies then have sex to see what its like from both perspectives.\\nthis might be a record for worst shower thought. \\nmy mates already like that, apparently a topnumber world champion at mario kart, so im sure when his kids are playing mario kartnumber, hell be telling that same ol story.\\nreal life is likenumber  diplomacy checks.\\nsmokinnumber while readin this, that cool? \\na pizza is just a modern version of a trencher from medieval times.\\nand edward snowden should do it.\\nthe kardashian’s can’t be that dumb, they’re  rich and famous and tricked everyone into caring about them.\\ni tell people not to talk to me until i’ve had a coffee, the key is not to drink coffee.\\nthe better yo'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)\n",
    "with open('mapping.json') as infile:\n",
    "    word_indices = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordvectors_mini = json.loads('wordvectors_mini.json')#.decode(\"utf-8\")\n",
    "# wordvectors_mini = json.load('test.json')\n",
    "with open('wordvectors_mini.json') as infile:\n",
    "    wordvectors_mini = json.load(infile)\n",
    "# text_generate_with_word(model, tokens, word_indices, 'pizza')\n",
    "# test_csv = pd.read_csv('wordvectors_mini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_csv.to_dict()#.shape#.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_csv\n",
    "# wordvectors_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "--- Generating with seed: \"as someone who doesn ’ t live in the usa , can someone explain what makes an old pizza pizza\"\n",
      "------ temperature: 1.0\n",
      "as someone who doesn ’ t live in the usa , can someone explain what makes an old pizza pizza . we are saying in instead a gave for a pretty a job . just a ’ movie started and the last part . a off into the where i have a and ( with an ? term https ."
     ]
    },
    {
     "data": {
      "text/plain": [
       "['as',\n",
       " 'someone',\n",
       " 'who',\n",
       " 'doesn',\n",
       " '’',\n",
       " 't',\n",
       " 'live',\n",
       " 'in',\n",
       " 'the',\n",
       " 'usa',\n",
       " ',',\n",
       " 'can',\n",
       " 'someone',\n",
       " 'explain',\n",
       " 'what',\n",
       " 'makes',\n",
       " 'an',\n",
       " 'old',\n",
       " 'pizza',\n",
       " 'pizza',\n",
       " '.',\n",
       " '.',\n",
       " 'we',\n",
       " 'are',\n",
       " 'saying',\n",
       " 'in',\n",
       " 'instead',\n",
       " 'a',\n",
       " 'gave',\n",
       " 'for',\n",
       " 'a',\n",
       " 'pretty',\n",
       " 'a',\n",
       " 'job',\n",
       " '.',\n",
       " 'just',\n",
       " 'a',\n",
       " '’',\n",
       " 'movie',\n",
       " 'started',\n",
       " 'and',\n",
       " 'the',\n",
       " 'last',\n",
       " 'part',\n",
       " '.',\n",
       " 'a',\n",
       " 'off',\n",
       " 'into',\n",
       " 'the',\n",
       " 'where',\n",
       " 'i',\n",
       " 'have',\n",
       " 'a',\n",
       " 'and',\n",
       " '(',\n",
       " 'with',\n",
       " 'an',\n",
       " '?',\n",
       " 'term',\n",
       " 'https',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generate_with_word(model, tokens, word_indices, 'pizza', maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
